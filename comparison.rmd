---
title: "Classifier Comparison"
author: "Rami Khalil"
date: "April 11, 2016"
output: html_document
---

```{r}
library(RWeka)
library(partykit)
library(dplyr)
library(knitr)
```

# 1. Initialization

```{r}
sonar <- read.csv("sonar/sonar.all-data", header = FALSE) %>% rename(V1 = V61, V61 = V1)
```

```{r}
compareWith10Fold <- function(classifier) {
  print(summary(classifier))
  kfold <- evaluate_Weka_classifier(classifier, numFolds = 10)
  print(kfold)
  return(kfold)
}

calculateMetrics <- function(kfold) {
  TP <- kfold$confusionMatrix[1, 1]
  TN <- kfold$confusionMatrix[2, 2]
  FP <- kfold$confusionMatrix[2, 1]
  FN <- kfold$confusionMatrix[1, 2]
  
  accuracy  <- (TP + TN) / (TP + TN + FP + FN)
  precision <- TP / (TP + FP)
  recall    <- TP / (TP + FN)
  f1        <- 2 * precision * recall / (precision + recall)
  
  res <- list(Accuracy = accuracy, Precision = precision, Recall = recall, F1 = f1)
  return(res)
}
```

# 2. C4.5 Classifier

```{r}
J48(V1 ~ ., sonar) %>%
  compareWith10Fold() %>%
  calculateMetrics()
```

Accuracy, Mean Error, precision, recall, f-score

# 3. Other Classifiers

## Random Forest

```{r}
RF <- make_Weka_classifier("weka/classifiers/trees/RandomForest")
RF(V1 ~ ., data = sonar) %>%
  compareWith10Fold() %>%
  calculateMetrics()
```

## Support Vector Machine

```{r}
SMO(V1 ~ ., data = sonar) %>%
  compareWith10Fold() %>%
  calculateMetrics()
```

## Naive Bayes Classifier

```{r}
NB <- make_Weka_classifier("weka/classifiers/bayes/NaiveBayes")
NB(V1 ~ ., data = sonar) %>%
  compareWith10Fold() %>%
  calculateMetrics()
```

## Neural Network

```{r}
MLP <- make_Weka_classifier("weka/classifiers/functions/MultilayerPerceptron")
MLP(V1 ~ ., data = sonar) %>%
  compareWith10Fold() %>%
  calculateMetrics()
```

## Bagging

```{r}
C45Bagging <- function(form, data, options = list(model = TRUE)) {
  return(Bagging(formula(form), data, control = Weka_control(W = "weka.classifiers.trees.J48"), options = options))
}
C45Bagging(V1 ~ ., data = sonar) %>%
  compareWith10Fold() %>%
  calculateMetrics()
```

## Boosting

```{r}
AdaBoostM1(V1 ~ ., data = sonar) %>%
  compareWith10Fold() %>%
  calculateMetrics()
```

# 4. Satistically Significant Results

## Datasets

```{r}
hepatitis <- read.csv("hepatitis/hepatitis.data", header = FALSE) %>% mutate(V1 = as.factor(V1))
spect <- 
  rbind(read.csv("spect/SPECT.train", header = FALSE), read.csv("spect/SPECT.test", header = FALSE)) %>%
  mutate(V1 = as.factor(V1))
pima <- read.csv("pima/pima-indians-diabetes.data", header = FALSE) %>%
  rename(V1 = V9, V9 = V1) %>%
  mutate(V1 = as.factor(V1))

datasets <- list(sonar, hepatitis, spect, pima)
names(datasets) <- c("Sonar", "Hepatitis", "Spect", "Pima")
```

## Methods

```{r}
testClassifiers <- function(dataset) {
  # The multi-layer perceptron classifier is very slow.
  # Uncomment both the algorithm and the name in the list to enable.
  # Will take ~1 minute to execute on a Core i7-5700HQ @ 2.7GHz
  algorithms <- c(
    J48,
    RF,
    SMO,
    NB,
    #MLP, # THIS IS VERY SLOW. UNCOMMENT AT YOUR OWN RISK!
    C45Bagging,
    AdaBoostM1)
  res <- c()
  for (func in algorithms) {
    subres <- c()
    for (i in 1:10) {
      subres <- c(
        subres, 
        list(
          calculateMetrics(
            evaluate_Weka_classifier(
              func(V1 ~ ., dataset, options = list(model = TRUE)),
              numFolds = 10))))
    }
    res <- c(res, list(subres))
  }
  names(res) <- c(
    "C4.5",
    "Random Forest",
    "SVM",
    "Naive Bayes",
    #"Neural Network", # THIS IS VERY SLOW. UNCOMMENT AT YOUR OWN RISK!
    "Bagging",
    "Boosting")
  
  res <- lapply(res, rbind_all)
  return(res)
}

pairwiseTesting <- function(calcs) {
  cols <-c("Accuracy", "Precision", "Recall", "F1")
  inv <- lapply(cols, function(x) {
    sapply(calcs, "[[", i = x) %>% data.frame()
  })
  names(inv) <- cols

  lapply(inv, function(metricDF) {
    sapply(metricDF, function(var1) {
      sapply(metricDF, function(var2) {
        tmp <- t.test(var1, var2)
        paste(
          sprintf("%.3f", tmp$statistic[[1]]),
          sprintf("%.3f", tmp$p.value),
          sep = ",p=")
      })
    }) %>% data.frame()
  })
}

kableMetrics <- function(results, caption) {
  results$Accuracy %>% kable(caption = paste(caption, "Accuracy")) %>% print()
  results$Precision %>% kable(caption = paste(caption, "Precision")) %>% print()
  results$Recall %>% kable(caption = paste(caption, "Recall")) %>% print()
  results$F1 %>% kable(caption = paste(caption, "F1 Score")) %>% print()
}
```

## Calcluations

```{r}
calculations <- lapply(datasets, testClassifiers)
```

```{r}
deepApply <- function(x, func = mean) {
  sapply(x, function(y) {
    sapply(y, func)
  })
}
metrics <- lapply(calculations, deepApply)

sapply(metrics, "[", i = "Accuracy", j = 1:6) %>% data.frame() %>% t() %>% kable(caption = "Accuracy")
sapply(metrics, "[", i = "Precision", j = 1:6) %>% data.frame() %>% t() %>% kable(caption = "Precision")
sapply(metrics, "[", i = "Recall", j = 1:6) %>% data.frame() %>% t() %>% kable(caption = "Recall")
sapply(metrics, "[", i = "F1", j = 1:6) %>% data.frame() %>% t() %>% kable(caption = "F1 Score")
```

## Comparisons

```{r, results='asis'}
pairwiseTesting(calculations$Sonar) %>% kableMetrics("Sonar Dataset")
pairwiseTesting(calculations$Hepatitis) %>% kableMetrics("Hepatitis Dataset")
pairwiseTesting(calculations$Spect) %>% kableMetrics("Spect Dataset")
pairwiseTesting(calculations$Pima) %>% kableMetrics("Pima Dataset")
```

## Interpretation

